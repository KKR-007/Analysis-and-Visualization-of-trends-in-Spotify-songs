# -*- coding: utf-8 -*-
"""DMV_Assignment_KR_IK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjZ6d3gvdW15Au4OenTr6FRVwvOdUV-S
"""



#Importing libraries
import pandas as pd
import ast
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import plotly.graph_objects as go
from sklearn.preprocessing import MinMaxScaler

# Load the dataset
file_path = 'data.csv'
data = pd.read_csv(file_path)

# Correct the date format
data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce',format='%m/%d/%y')
data['release_date'] = data['release_date'].apply(
    lambda x: x.replace(year=x.year - 100) if pd.notnull(x) and x.year > 2023 else x
)

# Convert stringified lists (e.g., 'artists') to actual lists
import ast
data['artists'] = data['artists'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

# Ensure numeric columns contain only valid numeric data
numeric_columns = ['duration_ms', 'acousticness', 'danceability', 'energy',
                   'instrumentalness', 'liveness', 'loudness', 'speechiness',
                   'tempo', 'valence', 'popularity']
for col in numeric_columns:
    data[col] = pd.to_numeric(data[col], errors='coerce')

# Remove rows with null values
data_cleaned = data.dropna()

# outlier detection
outlier_thresholds = {
    'duration_ms': (30_000, 600_000),  # Reasonable duration: 30 sec to 10 mins
    'loudness': (-35, 0),  # Reasonable loudness in dB
    'tempo': (40, 220),    # Reasonable tempo in BPM
}

# Function to filter outliers based on thresholds
def filter_outliers(data, thresholds):
    for column, (lower, upper) in thresholds.items():
        data = data[(data[column] >= lower) & (data[column] <= upper)]
    return data

# Apply outlier filtering
data_cleaned = filter_outliers(data_cleaned, outlier_thresholds)

# Drop unnecessary columns
columns_to_drop = ['mode', 'key', 'popularity', 'explicit']
data_cleaned = data_cleaned.drop(columns=columns_to_drop, errors='ignore')
data_cleaned['instrumentalness'] = data_cleaned['instrumentalness'].apply(lambda x: f"{x:.10f}" if pd.notnull(x) else x)

# Save the cleaned data to a new CSV file
output_path = 'cleaned_data.csv'
data_cleaned.to_csv(output_path, index=False)

# Display file path for access
print(f"\nCleaned dataset saved to: {output_path}")

# Load the dataset
file_path = 'cleaned_data.csv'
data = pd.read_csv(file_path)

# Convert release_date to datetime
data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')

# Normalize numerical columns for comparability
scaler = MinMaxScaler()
numerical_columns = ['duration_ms', 'loudness', 'tempo', 'acousticness',
                     'danceability', 'energy', 'instrumentalness',
                     'liveness', 'speechiness', 'valence']

data[numerical_columns] = scaler.fit_transform(data[numerical_columns])

# Sort and subset the data
recent_releases = data.sort_values('release_date', ascending=False).head(100)
entire_dataset = data

# Select features for the radar chart
selected_features = ['danceability', 'energy', 'speechiness', 'acousticness',
                     'instrumentalness', 'liveness', 'valence']
recent_means = recent_releases[selected_features].mean().tolist()
overall_means = entire_dataset[selected_features].mean().tolist()

# Create angles for radar chart
feature_count = len(selected_features)
angles = np.linspace(0, 2 * np.pi, feature_count, endpoint=False).tolist()
angles += angles[:1]

# Add first point to close the radar chart loop
recent_means += recent_means[:1]
overall_means += overall_means[:1]

# Create the radar chart using Plotly
fig = go.Figure()

# Add traces for recent releases
fig.add_trace(go.Scatterpolar(
    r=recent_means,
    theta=selected_features + [selected_features[0]],
    fill='toself',
    name='Entire Dataset',
    hovertemplate='<b>%{theta}</b>: %{r:.2f}<extra>Entire Dataset</extra>',
    line=dict(color='red', width=2),
    fillcolor='rgba(255, 0, 0, 0.2)',
    marker=dict(size=6)
))

# Add traces for entire dataset
fig.add_trace(go.Scatterpolar(
    r=overall_means,
    theta=selected_features + [selected_features[0]],
    fill='toself',
    name='100 Recently Released Songs',
    hovertemplate='<b>%{theta}</b>: %{r:.2f}<extra>Recently Released Songs</extra>',
    line=dict(color='blue', width=2),
    fillcolor='rgba(0, 0, 255, 0.2)',
    marker=dict(size=6)
))

# Update the layout for interactivity - The Final Spider Chart
fig.update_layout(
    polar=dict(
        bgcolor='lightgray',
        radialaxis=dict(
            visible=True,
            range=[0, 1],
            showline=True,
            showticklabels=True,
            tickangle=0,
            gridcolor='white'
        ),
        angularaxis=dict(
            showgrid=True,
            gridcolor='white'
        )
    ),
    title={
        'text': "Comparison of Song Features: Recent 100 vs. Entire Dataset",
        'y': 0.975,
        'x': 0.5,
        'xanchor': 'center',
        'yanchor': 'top'
    },
    legend=dict(
        x=0.85,
        y=1,
        bgcolor='rgba(255, 255, 255, 0.8)',
        bordercolor='black',
        borderwidth=1
    ),
    margin=dict(l=20, r=20, t=50, b=20),
    template='plotly_white',
    hovermode='closest'
)

# Show the interactive plot
fig.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the Spotify dataset
file_path = "cleaned_data.csv"  # Replace with your file path
spotify_data = pd.read_csv(file_path)

# Convert the release_date column to datetime
spotify_data['release_date'] = pd.to_datetime(spotify_data['release_date'])

# Sort the dataset by release_date in descending order and select the most recent 100 songs
recent_songs = spotify_data.sort_values(by='release_date', ascending=False).head(100)